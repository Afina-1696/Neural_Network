{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3399185,"sourceType":"datasetVersion","datasetId":2049052}],"dockerImageVersionId":30179,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing necessary libraries\n\n# Building deep learning models\nimport tensorflow as tf \nfrom tensorflow import keras \n# For accessing pre-trained models\nimport tensorflow_hub as hub \n# For separating train and test sets\nfrom sklearn.model_selection import train_test_split\n\n# For visualizations\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport PIL.Image as Image\nimport cv2\n\nimport os\nimport numpy as np\nimport pathlib","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:17.97112Z","iopub.execute_input":"2022-06-30T11:24:17.971562Z","iopub.status.idle":"2022-06-30T11:24:24.877779Z","shell.execute_reply.started":"2022-06-30T11:24:17.971417Z","shell.execute_reply":"2022-06-30T11:24:24.87699Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Preparing our dataset**","metadata":{}},{"cell_type":"code","source":"data_dir = \"../input/rice-image-dataset/Rice_Image_Dataset\" # Datasets path\ndata_dir = pathlib.Path(data_dir)\ndata_dir","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:24.879735Z","iopub.execute_input":"2022-06-30T11:24:24.880013Z","iopub.status.idle":"2022-06-30T11:24:24.892222Z","shell.execute_reply.started":"2022-06-30T11:24:24.879966Z","shell.execute_reply":"2022-06-30T11:24:24.891498Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Separating the categories**","metadata":{}},{"cell_type":"code","source":"arborio = list(data_dir.glob('Arborio/*'))[:600]\nbasmati = list(data_dir.glob('Basmati/*'))[:600]\nipsala = list(data_dir.glob('Ipsala/*'))[:600]\njasmine = list(data_dir.glob('Jasmine/*'))[:600]\nkaracadag = list(data_dir.glob('Karacadag/*'))[:600]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:24.893543Z","iopub.execute_input":"2022-06-30T11:24:24.895585Z","iopub.status.idle":"2022-06-30T11:24:27.580138Z","shell.execute_reply.started":"2022-06-30T11:24:24.895544Z","shell.execute_reply":"2022-06-30T11:24:27.579372Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Checking samples**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(ncols=5, figsize=(20,5))\nfig.suptitle('Rice Category')\narborio_image = img.imread(arborio[0])\nbasmati_image = img.imread(basmati[0])\nipsala_image = img.imread(ipsala[0])\njasmine_image = img.imread(jasmine[0])\nkaracadag_image = img.imread(karacadag[0])\n\nax[0].set_title('arborio')\nax[1].set_title('basmati')\nax[2].set_title('ipsala')\nax[3].set_title('jasmine')\nax[4].set_title('karacadag')\n\n\nax[0].imshow(arborio_image)\nax[1].imshow(basmati_image)\nax[2].imshow(ipsala_image)\nax[3].imshow(jasmine_image)\nax[4].imshow(karacadag_image)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:27.583208Z","iopub.execute_input":"2022-06-30T11:24:27.583469Z","iopub.status.idle":"2022-06-30T11:24:28.311508Z","shell.execute_reply.started":"2022-06-30T11:24:27.583419Z","shell.execute_reply":"2022-06-30T11:24:28.310818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Assigning a separate dictionary for images and their corresponding labels**","metadata":{}},{"cell_type":"code","source":"# Contains the images path\ndf_images = {\n    'arborio' : arborio,\n    'basmati' : basmati,\n    'ipsala' : ipsala,\n    'jasmine' : jasmine,\n    'karacadag': karacadag\n}\n\n# Contains numerical labels for the categories\ndf_labels = {\n    'arborio' : 0,\n    'basmati' : 1,\n    'ipsala' : 2,\n    'jasmine' : 3,\n    'karacadag': 4\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:28.31245Z","iopub.execute_input":"2022-06-30T11:24:28.312682Z","iopub.status.idle":"2022-06-30T11:24:28.31882Z","shell.execute_reply.started":"2022-06-30T11:24:28.312647Z","shell.execute_reply":"2022-06-30T11:24:28.317974Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Since the MobileNetv2 training images dimensions are 224 by 224 by 3, we have to reshape our categories into that**","metadata":{}},{"cell_type":"code","source":"img = cv2.imread(str(df_images['arborio'][0])) # Converting it into numerical arrays\nimg.shape # Its currently 250 by 250 by 3","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:28.320248Z","iopub.execute_input":"2022-06-30T11:24:28.321108Z","iopub.status.idle":"2022-06-30T11:24:28.346181Z","shell.execute_reply.started":"2022-06-30T11:24:28.32105Z","shell.execute_reply":"2022-06-30T11:24:28.345551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X, y = [], [] # X = images, y = labels\nfor label, images in df_images.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img, (224, 224)) # Resizing the images to be able to pass on MobileNetv2 model\n        X.append(resized_img) \n        y.append(df_labels[label])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:28.348673Z","iopub.execute_input":"2022-06-30T11:24:28.348857Z","iopub.status.idle":"2022-06-30T11:24:43.290404Z","shell.execute_reply.started":"2022-06-30T11:24:28.348835Z","shell.execute_reply":"2022-06-30T11:24:43.289602Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Splitting the data and standarization**","metadata":{}},{"cell_type":"code","source":"# Standarizing\nX = np.array(X)\nX = X/255\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:43.29185Z","iopub.execute_input":"2022-06-30T11:24:43.292103Z","iopub.status.idle":"2022-06-30T11:24:44.600025Z","shell.execute_reply.started":"2022-06-30T11:24:43.292069Z","shell.execute_reply":"2022-06-30T11:24:44.599264Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separating data into training, test and validation sets\nX_train, X_test_val, y_train, y_test_val = train_test_split(X, y)\nX_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:44.601307Z","iopub.execute_input":"2022-06-30T11:24:44.601581Z","iopub.status.idle":"2022-06-30T11:24:45.888276Z","shell.execute_reply.started":"2022-06-30T11:24:44.601545Z","shell.execute_reply":"2022-06-30T11:24:45.887482Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mobile_net = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4' # MobileNetv4 link\nmobile_net = hub.KerasLayer(\n        mobile_net, input_shape=(224,224, 3), trainable=False) # Removing the last layer","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:45.891295Z","iopub.execute_input":"2022-06-30T11:24:45.891671Z","iopub.status.idle":"2022-06-30T11:24:52.686838Z","shell.execute_reply.started":"2022-06-30T11:24:45.891629Z","shell.execute_reply":"2022-06-30T11:24:52.686113Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_label = 5 # number of labels\n\nmodel = keras.Sequential([\n    mobile_net,\n    keras.layers.Dense(num_label)\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:52.688254Z","iopub.execute_input":"2022-06-30T11:24:52.688537Z","iopub.status.idle":"2022-06-30T11:24:53.373799Z","shell.execute_reply.started":"2022-06-30T11:24:52.688498Z","shell.execute_reply":"2022-06-30T11:24:53.373079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n  optimizer=\"adam\",\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['acc'])\n\n\nhistory = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:24:53.37507Z","iopub.execute_input":"2022-06-30T11:24:53.375492Z","iopub.status.idle":"2022-06-30T11:25:41.820279Z","shell.execute_reply.started":"2022-06-30T11:24:53.375454Z","shell.execute_reply":"2022-06-30T11:25:41.819472Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:25:41.822489Z","iopub.execute_input":"2022-06-30T11:25:41.822773Z","iopub.status.idle":"2022-06-30T11:25:43.62705Z","shell.execute_reply.started":"2022-06-30T11:25:41.822737Z","shell.execute_reply":"2022-06-30T11:25:43.626288Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = model.predict(X_test, batch_size=64, verbose=1)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_test, y_pred_bool))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:25:43.629107Z","iopub.execute_input":"2022-06-30T11:25:43.629472Z","iopub.status.idle":"2022-06-30T11:25:46.504688Z","shell.execute_reply.started":"2022-06-30T11:25:43.629424Z","shell.execute_reply":"2022-06-30T11:25:46.503687Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from plotly.offline import iplot, init_notebook_mode\nimport plotly.express as px\nimport pandas as pd\n\ninit_notebook_mode(connected=True)\n\nacc = pd.DataFrame({'train': history.history['acc'], 'val': history.history['val_acc']})\n\nfig = px.line(acc, x=acc.index, y=acc.columns[0::], title='Training and Evaluation Accuracy every Epoch', markers=True)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:25:46.506542Z","iopub.execute_input":"2022-06-30T11:25:46.50683Z","iopub.status.idle":"2022-06-30T11:25:51.13197Z","shell.execute_reply.started":"2022-06-30T11:25:46.506789Z","shell.execute_reply":"2022-06-30T11:25:51.131262Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss = pd.DataFrame({'train': history.history['loss'], 'val': history.history['val_loss']})\n\nfig = px.line(loss, x=loss.index, y=loss.columns[0::], title='Training and Evaluation Loss every Epoch', markers=True)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T11:25:51.133525Z","iopub.execute_input":"2022-06-30T11:25:51.134001Z","iopub.status.idle":"2022-06-30T11:25:51.20844Z","shell.execute_reply.started":"2022-06-30T11:25:51.133959Z","shell.execute_reply":"2022-06-30T11:25:51.207487Z"},"trusted":true},"outputs":[],"execution_count":null}]}